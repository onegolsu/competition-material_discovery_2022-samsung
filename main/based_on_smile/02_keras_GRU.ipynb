{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# rdkits\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem,DataStructs\n",
    "from rdkit.Chem import MACCSkeys\n",
    "# ml\n",
    "import tensorflow as tf\n",
    "# etcs\n",
    "import warnings \n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/train_set.ReorgE.csv',index_col=0)\n",
    "test_df = pd.read_csv('./data/test_set.csv',index_col=0)\n",
    "submission = pd.read_csv('./data/sample_submission.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Reorg_g</th>\n",
       "      <th>Reorg_ex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_0</th>\n",
       "      <td>CC[C@H]1CCCCN1C(=O)[C@@H](C)OC(=O)c1c(C)oc(-n2...</td>\n",
       "      <td>0.631486</td>\n",
       "      <td>0.535060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_1</th>\n",
       "      <td>O[C@@H](CNC1CC1)CN1CCc2sccc2C1</td>\n",
       "      <td>0.825901</td>\n",
       "      <td>1.116781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_2</th>\n",
       "      <td>N#CCCNC(=O)[C@@]1(O)CCSC1</td>\n",
       "      <td>1.463943</td>\n",
       "      <td>0.964848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_3</th>\n",
       "      <td>COC[C@H]1CN(c2ccc(OCC[C@@H](C)O)cc2)C(=O)O1</td>\n",
       "      <td>0.166669</td>\n",
       "      <td>0.161458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_4</th>\n",
       "      <td>N#Cc1c(-c2ccccc2OCC(N)=O)[nH]c(C(N)=O)c1N</td>\n",
       "      <td>0.313820</td>\n",
       "      <td>0.338862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_18152</th>\n",
       "      <td>CC(=O)Nc1ccc2ccc3cccc4ccc1c2c34</td>\n",
       "      <td>0.146917</td>\n",
       "      <td>0.143084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_18153</th>\n",
       "      <td>CC(C)(C)c1ccccc1N(c1ccccc1)c1ccc(S(=O)(=O)c2cc...</td>\n",
       "      <td>0.612898</td>\n",
       "      <td>0.500668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_18154</th>\n",
       "      <td>CN(C)c1ccc(C(=O)Nc2ccccc2)cc1</td>\n",
       "      <td>1.218777</td>\n",
       "      <td>1.048954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_18155</th>\n",
       "      <td>c1ccc(N(c2ccccc2)c2ccc(-c3ncc(-c4ccc(-c5cnc(-c...</td>\n",
       "      <td>0.145292</td>\n",
       "      <td>0.182589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train_18156</th>\n",
       "      <td>COCCC1(CCOC)c2cc(-c3ccc(OC)cc3)ccc2-c2ccc(-c3c...</td>\n",
       "      <td>0.252465</td>\n",
       "      <td>0.306627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18157 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        SMILES   Reorg_g  \\\n",
       "index                                                                      \n",
       "train_0      CC[C@H]1CCCCN1C(=O)[C@@H](C)OC(=O)c1c(C)oc(-n2...  0.631486   \n",
       "train_1                         O[C@@H](CNC1CC1)CN1CCc2sccc2C1  0.825901   \n",
       "train_2                              N#CCCNC(=O)[C@@]1(O)CCSC1  1.463943   \n",
       "train_3            COC[C@H]1CN(c2ccc(OCC[C@@H](C)O)cc2)C(=O)O1  0.166669   \n",
       "train_4              N#Cc1c(-c2ccccc2OCC(N)=O)[nH]c(C(N)=O)c1N  0.313820   \n",
       "...                                                        ...       ...   \n",
       "train_18152                    CC(=O)Nc1ccc2ccc3cccc4ccc1c2c34  0.146917   \n",
       "train_18153  CC(C)(C)c1ccccc1N(c1ccccc1)c1ccc(S(=O)(=O)c2cc...  0.612898   \n",
       "train_18154                      CN(C)c1ccc(C(=O)Nc2ccccc2)cc1  1.218777   \n",
       "train_18155  c1ccc(N(c2ccccc2)c2ccc(-c3ncc(-c4ccc(-c5cnc(-c...  0.145292   \n",
       "train_18156  COCCC1(CCOC)c2cc(-c3ccc(OC)cc3)ccc2-c2ccc(-c3c...  0.252465   \n",
       "\n",
       "             Reorg_ex  \n",
       "index                  \n",
       "train_0      0.535060  \n",
       "train_1      1.116781  \n",
       "train_2      0.964848  \n",
       "train_3      0.161458  \n",
       "train_4      0.338862  \n",
       "...               ...  \n",
       "train_18152  0.143084  \n",
       "train_18153  0.500668  \n",
       "train_18154  1.048954  \n",
       "train_18155  0.182589  \n",
       "train_18156  0.306627  \n",
       "\n",
       "[18157 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffpp = 'pattern'\n",
    "train_fps = []\n",
    "train_y_g = []\n",
    "train_y_ex = []\n",
    "\n",
    "for index,row in train_df.iterrows():\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(row['SMILES'])\n",
    "        if ffpp == 'maccs':\n",
    "            fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "        elif ffpp == 'morgan':\n",
    "            fp = Chem.AllChem.GetMorganFingerprintAsBitVect(mol,4)\n",
    "        elif ffpp == 'rdkit':\n",
    "            fp = Chem.RDKFingerprint(mol)\n",
    "        elif ffpp == 'pattern':\n",
    "            fp = Chem.rdmolops.PatternFingerprint(mol)\n",
    "        elif ffpp == 'layerd':\n",
    "            fp = Chem.rdmolops.LayeredFingerprint(mol)\n",
    "        \n",
    "        train_fps.append(fp)\n",
    "        train_y_g.append(row['Reorg_g'])\n",
    "        train_y_ex.append(row['Reorg_ex'])\n",
    "    except:\n",
    "        pass\n",
    "np_train_fps = []\n",
    "for fp in train_fps:\n",
    "    arr = np.zeros((0,))\n",
    "    DataStructs.ConvertToNumpyArray(fp,arr)\n",
    "    np_train_fps.append(arr)\n",
    "\n",
    "np_train_fps_array = np.array(np_train_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_train_fps = []\n",
    "np_sum = []\n",
    "for fp in train_fps:\n",
    "    arr = np.zeros((0,))\n",
    "    DataStructs.ConvertToNumpyArray(fp,arr)\n",
    "    np_train_fps.append(arr)\n",
    "\n",
    "np_train_fps_array = np.array(np_train_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.DataFrame(np_train_fps_array)\n",
    "train_data.to_csv('train_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_train_fps_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np_train_fps_array[:,0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffpp = 'pattern'\n",
    "test_fps = []\n",
    "test_y = []\n",
    "for index,row in test_df.iterrows():\n",
    "    try:\n",
    "        mol = Chem.MolFromSmiles(row['SMILES'])\n",
    "        if ffpp == 'maccs':\n",
    "            fp = MACCSkeys.GenMACCSKeys(mol)\n",
    "        elif ffpp == 'morgan':\n",
    "            fp = Chem.AllChem.GetMorganFingerprintAsBitVect(mol,4)\n",
    "        elif ffpp == 'rdkit':\n",
    "            fp = Chem.RDKFingerprint(mol)\n",
    "        elif ffpp == 'pattern':\n",
    "            fp = Chem.rdmolops.PatternFingerprint(mol)\n",
    "        elif ffpp == 'layerd':\n",
    "            fp = Chem.rdmolops.LayeredFingerprint(mol)\n",
    "        \n",
    "        test_fps.append(fp)\n",
    "        test_y.append(row['y'])\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "np_test_fps = []\n",
    "np_test_sum = []\n",
    "for fp in test_fps:\n",
    "    arr = np.zeros((0,))\n",
    "    DataStructs.ConvertToNumpyArray(fp,arr)\n",
    "    np_test_fps.append(arr)\n",
    "    \n",
    "np_test_fps_array = np.array(np_test_fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_test_fps_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.DataFrame(np_test_fps_array)\n",
    "test_data.to_csv('test_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np_test_fps_array[:,0]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Dropout,BatchNormalization,LeakyReLU,PReLU,Embedding,LSTM,GRU,SimpleRNN\n",
    "from tensorflow_addons.layers import Maxout,GELU\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras.losses import MAE\n",
    "from tensorflow.nn import gelu\n",
    "\n",
    "from sklearn.model_selection import KFold,cross_val_score,cross_validate,train_test_split,StratifiedKFold\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = np_train_fps_array, np.array(train_y)\n",
    "print(X_train.shape,Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(30335,1,2048)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_test_fps_array = np_test_fps_array.reshape(602,1,2048)\n",
    "np_test_fps_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_num = 1\n",
    "MAE_score = []\n",
    "history_loss = []\n",
    "train_loss = []\n",
    "epochs = 100\n",
    "for train_idx, valid_idx in kf.split(X_train,Y_train):\n",
    "    print(f\"------------------fold{fold_num}----------------------\")\n",
    "    x_train, x_val = X_train[train_idx], X_train[valid_idx]\n",
    "    y_train, y_val = Y_train[train_idx], Y_train[valid_idx]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(2048,input_shape=(1,2048),return_sequences=True,activation='swish'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(GRU(2048,return_sequences=True,activation='swish'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(GRU(1024,return_sequences=True,activation='swish'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(GRU(1024))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1024,activation='swish'))\n",
    "    model.add(GELU(True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(2048,activation='swish'))\n",
    "    model.add(GELU(True))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(1024,activation='swish'))\n",
    "    model.add(GELU(True))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(512,activation='swish'))\n",
    "    model.add(GELU(True))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Dense(256,activation='swish'))\n",
    "    model.add(GELU(True))\n",
    "    model.add(Dense(1,kernel_initializer='normal'))\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00035),\n",
    "             loss='mean_absolute_error',\n",
    "             metrics=['mae'])\n",
    "        \n",
    "    earlystopper = tf.keras.callbacks.EarlyStopping(patience=10)\n",
    "    callbacks = tf.keras.callbacks.ModelCheckpoint(f'my_model_{fold_num}.h5',monitor='val_mae')\n",
    "    scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_mae',\n",
    "        factor=0.6,\n",
    "        patience=5,\n",
    "        verbose=1,\n",
    "        mode='auto',\n",
    "        min_lr=0.0001,\n",
    "        cooldown=3\n",
    "    )\n",
    "    \n",
    "    history = model.fit(x_train,y_train,validation_data=(x_val,y_val),\n",
    "                       batch_size=32,epochs=epochs,callbacks=[earlystopper,callbacks,scheduler])\n",
    "    history_loss.append(history.history['val_loss'])\n",
    "    train_loss.append(history.history['loss'])\n",
    "    model = tf.keras.models.load_model(f'./my_model_{fold_num}.h5')\n",
    "    \n",
    "    fold_num += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,15))\n",
    "plt.subplot(5,1,1)\n",
    "plt.plot(history_loss[0],label='deep_val_loss')\n",
    "plt.plot(train_loss[0],label='deep_train_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('val_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.subplot(5,1,2)\n",
    "plt.plot(history_loss[1],label='deep_val_loss')\n",
    "plt.plot(train_loss[1],label='deep_train_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('val_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.subplot(5,1,3)\n",
    "plt.plot(history_loss[2],label='deep_val_loss')\n",
    "plt.plot(train_loss[2],label='deep_train_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('val_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.subplot(5,1,4)\n",
    "plt.plot(history_loss[3],label='deep_val_loss')\n",
    "plt.plot(train_loss[3],label='deep_train_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('val_loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.subplot(5,1,5)\n",
    "plt.plot(history_loss[4],label='deep_val_loss')\n",
    "plt.plot(train_loss[4],label='deep_train_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('val_loss')\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_1 = []\n",
    "pred_2 = []\n",
    "pred_3 = []\n",
    "pred_4 = []\n",
    "pred_5 = []\n",
    "for i in range(5):\n",
    "    model = tf.keras.models.load_model(f'my_model_{i+1}.h5')\n",
    "    pred = model.predict(np_test_fps_array)\n",
    "    if i == 0:\n",
    "        pred_1 = pred\n",
    "    if i == 1:\n",
    "        pred_2 = pred\n",
    "    if i == 2:\n",
    "        pred_3 = pred\n",
    "    if i == 3:\n",
    "        pred_4 = pred\n",
    "    if i == 4:\n",
    "        pred_5 = pred\n",
    "\n",
    "final_pred = (pred_1+pred_2+pred_3+pred_4+pred_5)/5\n",
    "print(final_pred.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['ST1_GAP(eV)'] = final_pred\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('scheduler_leakyrelu_kfold_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
